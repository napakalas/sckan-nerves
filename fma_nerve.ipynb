{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e34839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utility import request_json, SOURCE_DIR, GENERATED_DIR\n",
    "import requests\n",
    "import rdflib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7548f",
   "metadata": {},
   "source": [
    "### Check from Scicrunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa73c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import get_existing_term, get_term_from_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93725cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load nerve list\n",
    "df = pd.read_csv(SOURCE_DIR / 'nervesWithVagus_annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987cd3e1",
   "metadata": {},
   "source": [
    "### Checking based on Term ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e26cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (fma_df_file := GENERATED_DIR/'fma_df.csv').exists():\n",
    "    fma_df = pd.read_csv(fma_df_file)\n",
    "else:\n",
    "    fma_df = df[df['Term ID'].astype(str).str.startswith('FMA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92282449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 786/786 [10:37<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "### Query the missing one from server\n",
    "fma_df['available'] = fma_df.progress_apply(\n",
    "    lambda row: get_existing_term(row['Term ID']) if pd.isna(row['available']) else row['available'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ### Query all to server\n",
    "# fma_df['available'] = fma_df['Term ID'].progress_apply(get_existing_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49bfb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_df.to_csv(GENERATED_DIR / 'fma_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee443a18",
   "metadata": {},
   "source": [
    "### Checking those without Term ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8cc7416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:34<00:00,  1.42it/s]\n",
      "/var/folders/zz/mk7_vrcn3r3gsbwr585w4blxzyk8xb/T/ipykernel_981/2597593306.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  null_df['available'] = null_df['Group name'].progress_apply(get_term_from_label)\n"
     ]
    }
   ],
   "source": [
    "null_df = df[df['Term ID'].isnull()]\n",
    "null_df['available'] = null_df['Group name'].progress_apply(get_term_from_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ec1175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df[null_df['available'].str.len() > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "895d2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.to_csv(GENERATED_DIR / 'null_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fe305",
   "metadata": {},
   "source": [
    "### Check from uberon, using hasDbXref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe383d8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### Dowload uberon.owl\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m### You can also downoad manually and store it in 'data/source' directory\u001b[39;00m\n\u001b[32m      4\u001b[39m uberon_url = \u001b[33m'\u001b[39m\u001b[33mhttps://data.bioontology.org/ontologies/UBERON/submissions/351/download?apikey=8b5b7825-538d-40e0-9e9e-5ab9274a9aeb\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43muberon_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m response.raise_for_status()\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(SOURCE_DIR / \u001b[33m'\u001b[39m\u001b[33muberon.owl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/requests/sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/requests/models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/urllib3/response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/urllib3/response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MapCore/sckan-nerves/.venv/lib/python3.12/site-packages/urllib3/response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "### Dowload uberon.owl\n",
    "### You can also downoad manually and store it in 'data/source' directory\n",
    "\n",
    "uberon_url = 'https://data.bioontology.org/ontologies/UBERON/submissions/351/download?apikey=8b5b7825-538d-40e0-9e9e-5ab9274a9aeb'\n",
    "response = requests.get(uberon_url)\n",
    "response.raise_for_status()\n",
    "with open(SOURCE_DIR / 'uberon.owl', \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d96b1779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N7538b30d60894ce38e88480896eb2808 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load uberon to rdflib graph\n",
    "g_uberon = rdflib.Graph()\n",
    "g_uberon.parse(SOURCE_DIR / 'uberon.owl', format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebbbb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBOINOWL = rdflib.Namespace(\"http://www.geneontology.org/formats/oboInOwl#\")\n",
    "\n",
    "def get_hasDbXref(term):\n",
    "    for s in g_uberon.subjects(predicate=OBOINOWL.hasDbXref, object=rdflib.Literal(term)):\n",
    "        if (s, rdflib.RDF.type, rdflib.OWL.Class) in g_uberon:\n",
    "            return str(s).replace('http://purl.obolibrary.org/obo/UBERON_', 'UBERON:')\n",
    "    return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4d7d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_df = fma_df.copy()\n",
    "fma_df['available'] = fma_df['available'].fillna(fma_df['Term ID'].apply(get_hasDbXref))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c0bc2",
   "metadata": {},
   "source": [
    "### Now check superclass and superbranch\n",
    "This is not the match but candidate to check\n",
    "\n",
    "And this take a lot of time, be patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30bdfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dowload fma.owl\n",
    "### You can also downoad manually and store it in 'data/source' directory\n",
    "\n",
    "fma_url = 'https://data.bioontology.org/ontologies/FMA/submissions/29/download?apikey=8b5b7825-538d-40e0-9e9e-5ab9274a9aeb'\n",
    "response = requests.get(fma_url)\n",
    "response.raise_for_status()\n",
    "with open(SOURCE_DIR / 'fma.owl', \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe12e8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd7ddb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ne8adeb1408ad4290b7cf9bb4500f6a21 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_fma = rdflib.Graph()\n",
    "g_fma.parse(SOURCE_DIR /'fma.owl', format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd88db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMA = rdflib.Namespace(\"http://purl.org/sig/ont/fma/fma\")\n",
    "RDFS = rdflib.Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "\n",
    "def curie(uri):\n",
    "    if isinstance(uri, rdflib.URIRef):\n",
    "        uri = str(uri)\n",
    "        if uri.startswith(\"http://purl.org/sig/ont/fma/fma\"):\n",
    "            return \"FMA:\" + uri.rsplit(\"fma\", 1)[-1]\n",
    "        elif uri.startswith(\"http://purl.obolibrary.org/obo/UBERON_\"):\n",
    "            return uri.replace('http://purl.obolibrary.org/obo/UBERON_', 'UBERON:')\n",
    "        return uri\n",
    "    return uri\n",
    "\n",
    "def clean_literal(val):\n",
    "    if isinstance(val, rdflib.Literal):\n",
    "        if val.datatype and val.datatype.endswith(\"integer\"):\n",
    "            return int(val)\n",
    "        elif val.datatype and val.datatype.endswith(\"float\"):\n",
    "            return float(val)\n",
    "        return str(val)\n",
    "    return val\n",
    "\n",
    "def get_related_terms(term):\n",
    "    query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX FMA: <http://purl.org/sig/ont/fma/fma>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "\n",
    "    SELECT ?superclass ?label ?rel (COUNT(?mid) AS ?level)\n",
    "    WHERE {{\n",
    "      {{\n",
    "        # Subclass path\n",
    "        {term} rdfs:subClassOf* ?mid .\n",
    "        ?mid rdfs:subClassOf* ?superclass .\n",
    "        BIND(\"subClassOf\" AS ?rel)\n",
    "      }}\n",
    "      UNION\n",
    "      {{\n",
    "        # branch_of restriction path\n",
    "        {term} rdfs:subClassOf* ?mid .\n",
    "        ?mid rdfs:subClassOf* [\n",
    "          owl:onProperty <http://purl.org/sig/ont/fma/branch> ;\n",
    "          owl:someValuesFrom ?superclass\n",
    "        ] .\n",
    "        BIND(\"branch_of\" AS ?rel)\n",
    "      }}\n",
    "\n",
    "      # Shared filters and info\n",
    "      OPTIONAL {{ ?superclass rdfs:label ?label }}\n",
    "      ?superclass a owl:Class .\n",
    "      ?superclass rdfs:subClassOf* FMA:65132 .\n",
    "    }}\n",
    "    GROUP BY ?superclass ?label ?type ?rel\n",
    "    ORDER BY ?level\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rows = []\n",
    "    for row in g_fma.query(query):\n",
    "        superclass = curie(row.superclass)\n",
    "        if superclass == 'FMA:65132':\n",
    "            continue\n",
    "        label = clean_literal(row.label)\n",
    "        rel = clean_literal(row.rel)\n",
    "        level = clean_literal(row.level)\n",
    "        rows.append((superclass, label, rel, level))\n",
    "\n",
    "    # return pd.DataFrame(rows, columns=[\"superclass\", \"label\", \"relation\", \"level\"])\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "549f0abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [35:37<00:00,  4.95s/it]\n"
     ]
    }
   ],
   "source": [
    "### now get superclass or super branch of terms (WARNING: this will be slow)\n",
    "candidate_terms = {}\n",
    "for term in tqdm(fma_df[fma_df['available'].isna()]['Term ID']):\n",
    "    candidate_terms[term] = get_related_terms(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9afdafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking existing terms: 100%|██████████| 1211/1211 [29:32<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "### populate existing terms, so can be access several time\n",
    "existing_terms = {}\n",
    "\n",
    "# Flatten and deduplicate candidate terms\n",
    "unique_rows = set(row for k_terms in candidate_terms.values() for row in k_terms)\n",
    "\n",
    "for row in tqdm(unique_rows, desc=\"Checking existing terms\"):\n",
    "    if row[0] in existing_terms: continue\n",
    "    ilx_terms = get_existing_term(row[0])\n",
    "    if isinstance(ilx_terms, list) and len(ilx_terms) > 0:\n",
    "        existing_terms[row[0]] = ilx_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fdf4646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [00:00<00:00, 9912.17it/s]\n"
     ]
    }
   ],
   "source": [
    "### then check from existing_terms\n",
    "ct_df = pd.DataFrame(columns=['Term ID', 'ILX superclass', 'FMA superclass', 'superclass label', 'relation', 'level'])\n",
    "missing_fmas = []\n",
    "for term, k_terms in tqdm(candidate_terms.items()):\n",
    "    for row in k_terms:\n",
    "        new_row = []\n",
    "        if (ilx_terms:=existing_terms.get(row[0])):\n",
    "            new_row = {\n",
    "                'Term ID': term,\n",
    "                'ILX superclass': ilx_terms,\n",
    "                'FMA superclass': row[0],\n",
    "                'superclass label': row[1],\n",
    "                'relation': row[2],\n",
    "                'level': row[3]\n",
    "            }\n",
    "            ct_df = pd.concat([ct_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            break\n",
    "        if not new_row:\n",
    "            missing_fmas += [term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce5f7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final step, for missing FMA terms check to UBERON\n",
    "\n",
    "OBOINOWL = rdflib.Namespace(\"http://www.geneontology.org/formats/oboInOwl#\")\n",
    "\n",
    "for term in missing_fmas:\n",
    "    for row in candidate_terms[term]:\n",
    "        for s in g_uberon.subjects(predicate=OBOINOWL.hasDbXref, object=rdflib.Literal(curie)):\n",
    "            if (s, rdflib.RDF.type, rdflib.OWL.Class) in g_uberon:\n",
    "                new_row = {\n",
    "                    'Term ID': term,\n",
    "                    'ILX superclass': [curie[s]],\n",
    "                    'FMA superclass': row[0],\n",
    "                    'superclass label': row[1],\n",
    "                    'relation': row[2],\n",
    "                    'level': row[3]\n",
    "                }\n",
    "                ct_df = pd.concat([ct_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                break  # break inner 'row' loop\n",
    "        else:\n",
    "            continue  # only runs if no break: keep checking rows\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4632ed",
   "metadata": {},
   "source": [
    "### Now combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35e875ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(fma_df[['Term ID', 'available']], on='Term ID', how='left')\n",
    "\n",
    "df_merged = df_merged.merge(null_df[['Group name', 'available']].rename(columns={'available': 'group_available'}),\n",
    "                            on='Group name', how='left')\n",
    "\n",
    "df_merged['available'] = df_merged['available'].fillna(df_merged['group_available'])\n",
    "\n",
    "df_merged.drop(columns=['group_available'], inplace=True)\n",
    "\n",
    "\n",
    "final_df = df_merged.merge(\n",
    "    ct_df,\n",
    "    on='Term ID',\n",
    "    how='left'  # or 'outer' if you want to preserve all terms from both\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96a2a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "### assign Term ID in final_df if available\n",
    "import numpy as np\n",
    "\n",
    "def pick_term_id(avail_list):\n",
    "    if not isinstance(avail_list, list):\n",
    "        return avail_list\n",
    "    for item in avail_list:\n",
    "        if isinstance(item, str) and item.startswith('UBERON'):\n",
    "            return item\n",
    "    for item in avail_list:\n",
    "        if isinstance(item, str) and item.startswith('ILX'):\n",
    "            return item\n",
    "    return avail_list[0]\n",
    "\n",
    "# Only update where 'Term ID' is NaN\n",
    "final_df['Term ID'] = final_df.apply(\n",
    "    lambda row: pick_term_id(row['available']) if pd.isna(row['Term ID']) else row['Term ID'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a403db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns={'Unnamed: 2': 'Note'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bbbb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop_duplicates(subset=['Term ID', 'Group name']).to_csv(GENERATED_DIR / 'mapped_fma_nerves.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
